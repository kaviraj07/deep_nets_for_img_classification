{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeper Networks for Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG Model for Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Code by: Kaviraj Gosaye\n",
    "- Student ID: 220575371"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torchinfo import summary\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform PIL image to tensor and normalize\n",
    "transform = transforms.Compose([transforms.Grayscale(num_output_channels=3), transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# load mnist dataset\n",
    "train_set = torchvision.datasets.MNIST(root='./datasets', train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.MNIST(root='./datasets', train=False, download=True, transform=transform)\n",
    "                                    \n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract one sample from the training set\n",
    "dataiter = iter(train_loader)\n",
    "# images, labels = dataiter.next()\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# plot the image\n",
    "def imshow(img):\n",
    "    # reverse normalization\n",
    "    img = img / 2 + 0.5\n",
    "    # convert tensor to numpy array\n",
    "    npimg = img.numpy()\n",
    "    # rearrange the dimensions to match matplotlib format\n",
    "    # matplotlib:   H x W x C\n",
    "    # torch:        C x H x W\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the VGG16 layers#\n",
    "VGG16_layers = [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, \"M\", 512, 512, 512, \"M\", 512, 512, 512, \"M\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a class of the VGG16 model\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=1000):\n",
    "        super(VGG16, self).__init__()\n",
    "        # inpuy layer\n",
    "        self.in_channels = in_channels\n",
    "        # hidden layers\n",
    "        self.hidden_layers = self.conv_layers(VGG16_layers)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        # output layer\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden_layers(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        # x = x.reshape(x.shape[0], -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    # function to create the hidden convolutional layers\n",
    "    def conv_layers(self, layer_types):\n",
    "        layers = []\n",
    "        in_channels = self.in_channels\n",
    "\n",
    "        for layer in layer_types:\n",
    "            if type(layer) == int:\n",
    "                out_channels = layer\n",
    "\n",
    "                layers += [ nn.Conv2d( in_channels=in_channels, out_channels=out_channels, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), ), nn.BatchNorm2d(layer), nn.ReLU()]\n",
    "                in_channels = layer\n",
    "            elif layer == \"M\":\n",
    "                layers += [nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))]\n",
    "\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the device to cuda if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# creating instance of model and setting it to the device\n",
    "vgg16 = VGG16().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the model\n",
    "info = summary(vgg16, (3,3, 224, 224), col_names = ('input_size', 'output_size', 'num_params', 'kernel_size'))\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# training the model\n",
    "start = time.time()\n",
    "\n",
    "num_epochs = 10\n",
    "losses = []\n",
    "train_accs = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = vgg16(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # cumulative loss\n",
    "        running_loss += loss.item()\n",
    "        # printing the average loss every 100 mini-batches\n",
    "        if i % 100 == 99:\n",
    "            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 100}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "    correct = 0.0\n",
    "    pred = outputs.argmax(dim=1, keepdim=True)\n",
    "    # reshaping the labels to match the shape of the predictions\n",
    "    # comparing the predictions to the labels using element-wise comparison\n",
    "    # summing the correct predictions\n",
    "    correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "    train_acc = 100. * correct / len(outputs)\n",
    "    train_accs.append(train_acc)\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "print(f\"Finished Training after {time.time() - start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "    test_loss = 0\n",
    "\n",
    "    # Using test set\n",
    "    for data in test_loader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = vgg16(images)\n",
    "        \n",
    "        # Calculate the test loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Get the predicted labels\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Update the total and correct predictions\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Append the predicted and true labels\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = 100 * correct / total\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "# Print the accuracy and test loss\n",
    "print(f\"Accuracy on the test data: {accuracy}%\")\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy\n",
    "plt.plot(train_accs)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
