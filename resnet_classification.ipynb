{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeper Networks for Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ResNet50 Model for Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Code by: Kaviraj Gosaye\n",
    "- Student ID: 220575371"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torchinfo import summary\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform PIL image to tensor and normalize\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3), \n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# load mnist dataset\n",
    "train_set = torchvision.datasets.MNIST(root='./datasets', train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.MNIST(root='./datasets', train=False, download=True, transform=transform)\n",
    "                                    \n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract one sample from the training set\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# plot the image\n",
    "def imshow(img):\n",
    "    # reverse normalization\n",
    "    img = img / 2 + 0.5\n",
    "    # convert tensor to numpy array\n",
    "    npimg = img.numpy()\n",
    "    # rearrange the dimensions to match matplotlib format\n",
    "    # matplotlib:   H x W x C\n",
    "    # torch:        C x H x W\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "\n",
    "    # self, input channels, number of channels for 3x3 conv, expansion factor, stride\n",
    "    def __init__(self, in_channels, intermediate_channels, expansion, stride):\n",
    "\n",
    "        super(Bottleneck,self).__init__()\n",
    "\n",
    "        self.expansion = expansion\n",
    "        self.in_channels = in_channels\n",
    "        self.intermediate_channels = intermediate_channels\n",
    "        \n",
    "        # if identity mapping is possible\n",
    "        if self.in_channels == self.intermediate_channels*self.expansion:\n",
    "            self.identity = True\n",
    "        # else projection mapping is required\n",
    "        else:\n",
    "            self.identity = False\n",
    "            projection_layer = []\n",
    "            projection_layer.append(nn.Conv2d(in_channels=self.in_channels, out_channels=self.intermediate_channels*self.expansion, kernel_size=1, stride=stride, padding=0, bias=False ))\n",
    "            projection_layer.append(nn.BatchNorm2d(self.intermediate_channels*self.expansion))\n",
    "            self.projection = nn.Sequential(*projection_layer)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "        self.conv1_1x1 = nn.Conv2d(in_channels=self.in_channels, out_channels=self.intermediate_channels, kernel_size=1, stride=1, padding=0, bias=False )\n",
    "        self.batchnorm1 = nn.BatchNorm2d(self.intermediate_channels)\n",
    "        \n",
    "        # 3x3\n",
    "        self.conv2_3x3 = nn.Conv2d(in_channels=self.intermediate_channels, out_channels=self.intermediate_channels, kernel_size=3, stride=stride, padding=1, bias=False )\n",
    "        self.batchnorm2 = nn.BatchNorm2d(self.intermediate_channels)\n",
    "        \n",
    "        # 1x1\n",
    "        self.conv3_1x1 = nn.Conv2d(in_channels=self.intermediate_channels, out_channels=self.intermediate_channels*self.expansion, kernel_size=1, stride=1, padding=0, bias=False )\n",
    "        self.batchnorm3 = nn.BatchNorm2d( self.intermediate_channels*self.expansion )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # store input for pre-final layer\n",
    "        in_x = x\n",
    "\n",
    "        x = self.relu(self.batchnorm1(self.conv1_1x1(x)))\n",
    "\n",
    "        x = self.relu(self.batchnorm2(self.conv2_3x3(x)))\n",
    "        \n",
    "        x = self.batchnorm3(self.conv3_1x1(x))\n",
    "\n",
    "        # identity or projected mapping\n",
    "        if self.identity:\n",
    "            x += in_x\n",
    "        else:\n",
    "            x += self.projection(in_x)\n",
    "\n",
    "        # final relu\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(nn.Module):\n",
    "    # self, number of channels, image channels (3), output\n",
    "    def __init__(self, resnet_channels, in_channels, num_classes):\n",
    "\n",
    "        super(ResNet50,self).__init__()\n",
    "        self.channels_list = resnet_channels[0]\n",
    "        self.repeatition_list = resnet_channels[1]\n",
    "        self.expansion = resnet_channels[2]\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False )\n",
    "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "\n",
    "        self.block1 = self.create_blocks( 64 , self.channels_list[0], self.repeatition_list[0], self.expansion, stride=1 )\n",
    "        self.block2 = self.create_blocks( self.channels_list[0]*self.expansion , self.channels_list[1], self.repeatition_list[1], self.expansion, stride=2 )\n",
    "        self.block3 = self.create_blocks( self.channels_list[1]*self.expansion , self.channels_list[2], self.repeatition_list[2], self.expansion, stride=2 )\n",
    "        self.block4 = self.create_blocks( self.channels_list[2]*self.expansion , self.channels_list[3], self.repeatition_list[3], self.expansion, stride=2 )\n",
    "\n",
    "        self.average_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear( self.channels_list[3]*self.expansion , num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.batchnorm1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.block1(x)\n",
    "        \n",
    "        x = self.block2(x)\n",
    "        \n",
    "        x = self.block3(x)\n",
    "        \n",
    "        x = self.block4(x)\n",
    "        \n",
    "        x = self.average_pool(x)\n",
    "\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    # self, input channels, intermediate channels, number of repeats, expansion factor, stride\n",
    "    def create_blocks(self, in_channels, intermediate_channels, num_repeat, expansion, stride):\n",
    "        layers = [] \n",
    "        layers.append(Bottleneck(in_channels,intermediate_channels,expansion,stride=stride))\n",
    "        for num in range(1,num_repeat):\n",
    "            layers.append(Bottleneck(intermediate_channels*expansion,intermediate_channels,expansion,stride=1))\n",
    "\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the device to cuda if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating instance of model and setting it to the device\n",
    "architecture = ([64,128,256,512], [3,4,6,3], 4)\n",
    "resnet_50 = ResNet50(architecture , in_channels=3, num_classes=1000).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the model\n",
    "info = summary(resnet_50, (3,3, 224, 224), col_names = ('input_size', 'output_size', 'num_params', 'kernel_size'))\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet_50.parameters(), lr=0.001)\n",
    "\n",
    "# training the model\n",
    "start = time.time()\n",
    "\n",
    "num_epochs = 1\n",
    "losses = []\n",
    "train_accs = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = resnet_50(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # cumulative loss\n",
    "        running_loss += loss.item()\n",
    "        # printing the average loss every 100 mini-batches\n",
    "        if i % 100 == 99:\n",
    "            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 100}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "    correct = 0.0\n",
    "    pred = outputs.argmax(dim=1, keepdim=True)\n",
    "    # reshaping the labels to match the shape of the predictions\n",
    "    # comparing the predictions to the labels using element-wise comparison\n",
    "    # summing the correct predictions\n",
    "    correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "    train_acc = 100. * correct / len(outputs)\n",
    "    train_accs.append(train_acc)\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "print(f\"Finished Training after {time.time() - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model after training\n",
    "torch.save(resnet_50, \"./Models/resnet_50_mnist.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_50.eval()\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "    test_loss = 0\n",
    "\n",
    "    # Using test set\n",
    "    for data in test_loader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = resnet_50(images)\n",
    "        \n",
    "        # Calculate the test loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Get the predicted labels\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Update the total and correct predictions\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Append the predicted and true labels\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = 100 * correct / total\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "# Print the accuracy and test loss\n",
    "print(f\"Accuracy on the test data: {accuracy}%\")\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy\n",
    "plt.plot(train_accs)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to tensors\n",
    "pred_labels_tensor = torch.tensor(predicted_labels)\n",
    "true_labels_tensor = torch.tensor(true_labels)\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision = precision_score(true_labels_tensor, pred_labels_tensor, average='weighted')\n",
    "recall = recall_score(true_labels_tensor, pred_labels_tensor, average='weighted')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
