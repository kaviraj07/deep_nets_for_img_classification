{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeper Networks for Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## MobileNetV2 Model for MNIST Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Code by: Kaviraj Gosaye\n",
    "- Student ID: 220575371"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU details\n",
    "output = !nvidia-smi\n",
    "for line in output:\n",
    "    print(line)\n",
    "    if line.strip() == \"\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "# Get virtual memory information\n",
    "virtual_memory = psutil.virtual_memory()\n",
    "v_mem = virtual_memory.available / (1024 ** 3)\n",
    "\n",
    "# Print available virtual memory\n",
    "print(\"Available virtual memory:\", v_mem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torchinfo import summary\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import torchvision.ops.misc as misc\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform PIL image to tensor and normalize\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "# load mnist dataset\n",
    "train_set = torchvision.datasets.MNIST(root='../datasets', train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.MNIST(root='../datasets', train=False, download=True, transform=transform)\n",
    "                                    \n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract one sample from the training set\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# plot the image\n",
    "def imshow(img):\n",
    "    # reverse normalization\n",
    "    img = img / 2 + 0.5\n",
    "    # convert tensor to numpy array\n",
    "    npimg = img.numpy()\n",
    "    # rearrange the dimensions to match matplotlib format\n",
    "    # matplotlib:   H x W x C\n",
    "    # torch:        C x H x W\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = int(round(inp * expand_ratio))\n",
    "        self.use_res_connect = self.stride == 1 and inp == oup\n",
    "\n",
    "        layers = []\n",
    "        if expand_ratio != 1:\n",
    "            layers.append(misc.Conv2dNormActivation(inp, hidden_dim, kernel_size=1, norm_layer=nn.BatchNorm2d, activation_layer=nn.ReLU6))\n",
    "        layers.extend([\n",
    "            misc.Conv2dNormActivation(hidden_dim, hidden_dim, stride=stride, groups=hidden_dim, norm_layer=nn.BatchNorm2d, activation_layer=nn.ReLU6),\n",
    "            misc.Conv2dNormActivation(hidden_dim, oup, kernel_size=1, norm_layer=nn.BatchNorm2d, activation_layer=nn.Identity)\n",
    "        ])\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=1000, width_mult=1.0):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        self.cfgs = [\n",
    "            # t, c, n, s\n",
    "            [1, 16, 1, 1],\n",
    "            [6, 24, 2, 2],\n",
    "            [6, 32, 3, 2],\n",
    "            [6, 64, 4, 2],\n",
    "            [6, 96, 3, 1],\n",
    "            [6, 160, 3, 2],\n",
    "            [6, 320, 1, 1],\n",
    "        ]\n",
    "\n",
    "        input_channel = 32\n",
    "        # change input channels to 1, added padding=1\n",
    "        layers = [misc.Conv2dNormActivation(1, input_channel, kernel_size=3, stride=2, padding=1, norm_layer=nn.BatchNorm2d, activation_layer=nn.ReLU6)]\n",
    "\n",
    "        for t, c, n, s in self.cfgs:\n",
    "            output_channel = int(c * width_mult)\n",
    "            for i in range(n):\n",
    "                stride = s if i == 0 else 1\n",
    "                layers.append(InvertedResidual(input_channel, output_channel, stride, expand_ratio=t))\n",
    "                input_channel = output_channel\n",
    "\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(input_channel, num_classes)\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the device to cuda if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating instance of model and setting it to the device\n",
    "mobilenetv2 = MobileNetV2(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the model\n",
    "info = summary(mobilenetv2, (1, 1, 28, 28), col_names = ('input_size', 'output_size', 'num_params', 'kernel_size'))\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mobilenetv2.parameters(), lr=0.0001)\n",
    "\n",
    "# open log file in write mode\n",
    "log_file = open(\"../logs/mobilenetv2_mnist_log.txt\", \"w\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "test_losses = []\n",
    "test_accs = []\n",
    "\n",
    "test_correct = 0\n",
    "total = 0\n",
    "\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_train_loss = 0.0\n",
    "    running_train_acc = 0.0\n",
    "    running_test_loss = 0.0\n",
    "    running_test_acc = 0.0\n",
    "    correct = 0.0\n",
    "    avg_test_loss = 0\n",
    "    batch_loss = 0.0\n",
    "    batch_acc = 0.0\n",
    "\n",
    "    # setting the model to train mode\n",
    "    mobilenetv2.train()\n",
    "    \n",
    "    # loop over the training set\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = mobilenetv2(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # cumulative loss\n",
    "        running_train_loss += loss.item()\n",
    "        # batch loss for logging\n",
    "        batch_loss += loss.item()\n",
    "\n",
    "        # cumulative accuracy\n",
    "        pred = outputs.argmax(dim=1, keepdim=True)\n",
    "\n",
    "        # reshaping the labels to match the shape of the predictions\n",
    "        # comparing the predictions to the labels using element-wise comparison\n",
    "        # summing the correct predictions\n",
    "        correct = pred.eq(labels.view_as(pred)).sum().item()\n",
    "        running_train_acc += 100. * (correct / len(pred))\n",
    "\n",
    "        # batch accuracy for logging\n",
    "        batch_acc += 100. * (correct / len(pred))\n",
    "        # printing the average loss every 100 mini-batches\n",
    "        if i % 100 == 99:\n",
    "             # Get current timestamp\n",
    "            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            # Write loss to log file\n",
    "            log_file.write(f\"{timestamp} - [{epoch + 1}, {i + 1}] loss: {batch_loss/100} accuracy: {batch_acc/100}\\n\")\n",
    "            print(f\"[{epoch + 1}, {i + 1}] loss: {batch_loss/100} accuracy: {batch_acc/100}\")\n",
    "            batch_loss = 0.0\n",
    "            batch_acc = 0.0\n",
    "\n",
    "    train_accs.append(running_train_acc/len(train_loader))\n",
    "    train_losses.append(running_train_loss/len(train_loader))\n",
    "\n",
    "\n",
    "    ##############################\n",
    "\n",
    "    # setting the model to evaluation mode\n",
    "    mobilenetv2.to(device)\n",
    "    mobilenetv2.eval()\n",
    "\n",
    "\n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        # Using test set\n",
    "        for i, data in enumerate(test_loader, 0):\n",
    "\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = mobilenetv2(images)\n",
    "            \n",
    "            # Calculate the test loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            avg_test_loss += loss.item()\n",
    "\n",
    "            # Get the predicted labels\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # Update the total and correct predictions\n",
    "            total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Append the predicted and true labels to be used for confusion matrix\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            running_test_loss += loss.item()\n",
    "            running_test_acc += 100 * test_correct / total\n",
    "\n",
    "           \n",
    "        test_losses.append(running_test_loss/len(test_loader))\n",
    "        test_accs.append(running_test_acc/len(test_loader))\n",
    "\n",
    "training_time = f'{(time.time() - start)/60.0:.2f}'\n",
    "log_file.write(f\"Finished Training after {training_time} minutes\\n\")\n",
    "print(f\"Finished Training after {training_time} minutes\")\n",
    "\n",
    "# Close the log file\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model after training\n",
    "torch.save(mobilenetv2, \"../Models/mobilenet_v2_mnist.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Results and Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print final accuracy\n",
    "# get the final value of train_acc\n",
    "\n",
    "print(f\"Train Accuracy: {train_accs[-1]} %\")\n",
    "print(f\"Test Accuracy: {test_accs[-1]} %\")\n",
    "\n",
    "print(f\"Train Loss: {train_losses[-1]}\")\n",
    "print(f\"Test Loss: {test_losses[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix - MobileNetV2 on MNIST\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and test loss over epochs\n",
    "plt.plot(train_losses, label=\"Training Loss\")\n",
    "plt.plot(test_losses, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss over Epochs - MobileNetV2 on MNIST\")\n",
    "plt.legend()\n",
    "# save the plot\n",
    "plt.savefig(\"./plots/Loss_MobileNetV2_MNIST.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training accuracy and test accuracy over epochs\n",
    "plt.plot(train_accs, label=\"Training Accuracy\")\n",
    "plt.plot(test_accs, label=\"Test Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy over Epochs - MobileNetV2 on MNIST\")\n",
    "plt.legend()\n",
    "plt.savefig(\"./plots/Acc_MobileNetV2_MNIST.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print classification report\n",
    "cr = classification_report(true_labels, predicted_labels)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading some images from the test set\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=30,shuffle=False)\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, true_labels = next(dataiter)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes of mnist\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotter function to plot the images\n",
    "def plotter(images, true_labels, predicted_labels):\n",
    "    correct = 0\n",
    "    num_images = len(images)\n",
    "    num_rows = (num_images) // 5\n",
    "    fig, axs = plt.subplots(num_rows, 5, figsize=(15, 20))\n",
    "    # setting the title\n",
    "    fig.suptitle('True Label - [Predicted Labels]', fontsize=20)\n",
    "\n",
    "    for ind in range(num_images):\n",
    "        # plot image\n",
    "        img = images[ind].permute(1, 2, 0) / 2 + 0.5\n",
    "        ax = axs[ind // 5, ind % 5]\n",
    "        ax.imshow(img, cmap='gray')\n",
    "\n",
    "        # left - true label, right - predicted label\n",
    "        if classes[true_labels[ind]] == classes[predicted_labels[ind]]:\n",
    "            color = 'green'\n",
    "            title = classes[true_labels[ind]] + ' - [' + classes[predicted_labels[ind]] + ']'\n",
    "            ax.set_title(title, color=color)\n",
    "            correct += 1\n",
    "        else:\n",
    "            color = 'red'\n",
    "            title = classes[true_labels[ind]] + ' - [' + classes[predicted_labels[ind]] + ']'\n",
    "            ax.set_title(title, color=color)        \n",
    "\n",
    "    plt.tight_layout(pad=2.0)\n",
    "    plt.show()\n",
    "    print('Number of correct predictions: ', correct)\n",
    "    print('Number of wrong predictions: ', num_images - correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model to predict images label\n",
    "mobilenetv2.eval()\n",
    "mobilenetv2.to('cpu')\n",
    "outputs = mobilenetv2(images)\n",
    "_, predicted_labels = torch.max(outputs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the images and predictions\n",
    "plotter(images, true_labels, predicted_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
