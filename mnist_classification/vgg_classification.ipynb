{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeper Networks for Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 Model for MNIST Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Code by: Kaviraj Gosaye\n",
    "- Student ID: 220575371"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU details\n",
    "output = !nvidia-smi\n",
    "for line in output:\n",
    "    print(line)\n",
    "    if line.strip() == \"\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "# Get virtual memory information\n",
    "virtual_memory = psutil.virtual_memory()\n",
    "v_mem = virtual_memory.available / (1024 ** 3)\n",
    "\n",
    "# Print available virtual memory\n",
    "print(\"Available virtual memory:\", v_mem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torchinfo import summary\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform PIL image to tensor and normalize\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "# load mnist dataset\n",
    "train_set = torchvision.datasets.MNIST(root='../datasets', train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.MNIST(root='../datasets', train=False, download=True, transform=transform)\n",
    "                                    \n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract one sample from the training set\n",
    "dataiter = iter(train_loader)\n",
    "# images, labels = dataiter.next()\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# plot the image\n",
    "def imshow(img):\n",
    "    # reverse normalization\n",
    "    img = img / 2 + 0.5\n",
    "    # convert tensor to numpy array\n",
    "    npimg = img.numpy()\n",
    "    # rearrange the dimensions to match matplotlib format\n",
    "    # matplotlib:   H x W x C\n",
    "    # torch:        C x H x W\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the VGG16 layers\n",
    "VGG16_layers = [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, \"A\", 512, 512, 512, \"A\", 512, 512, 512, \"M\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a class of the VGG16 model\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=1000):\n",
    "        super(VGG16, self).__init__()\n",
    "        # inpuy layer\n",
    "        self.in_channels = in_channels\n",
    "        # hidden layers\n",
    "        self.hidden_layers = self.conv_layers(VGG16_layers)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        # output layer\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden_layers(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    # function to create the hidden convolutional layers\n",
    "    def conv_layers(self, layer_types):\n",
    "        layers = []\n",
    "        in_channels = self.in_channels\n",
    "\n",
    "        for layer in layer_types:\n",
    "            if type(layer) == int:\n",
    "                out_channels = layer\n",
    "                layers += [ nn.Conv2d( in_channels=in_channels, out_channels=out_channels, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), ), nn.BatchNorm2d(layer), nn.ReLU()]\n",
    "                in_channels = layer\n",
    "            # max pooling layer\n",
    "            elif layer == \"M\":\n",
    "                layers += [nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))]\n",
    "            # average pooling layer\n",
    "            elif layer == \"A\":\n",
    "                layers += [nn.AdaptiveAvgPool2d((14,14))]\n",
    "\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the device to cuda if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# creating instance of model and setting it to the device\n",
    "vgg16 = VGG16(in_channels=1, num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the model\n",
    "info = summary(vgg16, (1, 1, 28, 28), col_names = ('input_size', 'output_size', 'num_params', 'kernel_size'))\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(vgg16.parameters(), lr=0.0001)\n",
    "\n",
    "# open log file in write mode\n",
    "log_file = open(\"../logs/vgg16_mnist_log.txt\", \"w\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "test_losses = []\n",
    "test_accs = []\n",
    "\n",
    "test_correct = 0\n",
    "total = 0\n",
    "\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_train_loss = 0.0\n",
    "    running_train_acc = 0.0\n",
    "    running_test_loss = 0.0\n",
    "    running_test_acc = 0.0\n",
    "    correct = 0.0\n",
    "    avg_test_loss = 0\n",
    "    batch_loss = 0.0\n",
    "    batch_acc = 0.0\n",
    "\n",
    "    # setting the model to train mode\n",
    "    vgg16.train()\n",
    "    \n",
    "    # loop over the training set\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = vgg16(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # cumulative loss\n",
    "        running_train_loss += loss.item()\n",
    "        # batch loss for logging\n",
    "        batch_loss += loss.item()\n",
    "\n",
    "        # cumulative accuracy\n",
    "        pred = outputs.argmax(dim=1, keepdim=True)\n",
    "\n",
    "        # reshaping the labels to match the shape of the predictions\n",
    "        # comparing the predictions to the labels using element-wise comparison\n",
    "        # summing the correct predictions\n",
    "        correct = pred.eq(labels.view_as(pred)).sum().item()\n",
    "        running_train_acc += 100. * (correct / len(pred))\n",
    "\n",
    "        # batch accuracy for logging\n",
    "        batch_acc += 100. * (correct / len(pred))\n",
    "        # printing the average loss every 100 mini-batches\n",
    "        if i % 100 == 99:\n",
    "             # Get current timestamp\n",
    "            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            # Write loss to log file\n",
    "            log_file.write(f\"{timestamp} - [{epoch + 1}, {i + 1}] loss: {batch_loss/100} accuracy: {batch_acc/100}\\n\")\n",
    "            print(f\"[{epoch + 1}, {i + 1}] loss: {batch_loss/100} accuracy: {batch_acc/100}\")\n",
    "            batch_loss = 0.0\n",
    "            batch_acc = 0.0\n",
    "\n",
    "    train_accs.append(running_train_acc/len(train_loader))\n",
    "    train_losses.append(running_train_loss/len(train_loader))\n",
    "\n",
    "\n",
    "    ##############################\n",
    "\n",
    "    # setting the model to evaluation mode\n",
    "    vgg16.to(device)\n",
    "    vgg16.eval()\n",
    "\n",
    "\n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        # Using test set\n",
    "        for i, data in enumerate(test_loader, 0):\n",
    "\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = vgg16(images)\n",
    "            \n",
    "            # Calculate the test loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            avg_test_loss += loss.item()\n",
    "\n",
    "            # Get the predicted labels\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # Update the total and correct predictions\n",
    "            total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Append the predicted and true labels to be used for confusion matrix\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            running_test_loss += loss.item()\n",
    "            running_test_acc += 100 * test_correct / total\n",
    "\n",
    "           \n",
    "        test_losses.append(running_test_loss/len(test_loader))\n",
    "        test_accs.append(running_test_acc/len(test_loader))\n",
    "\n",
    "training_time = f'{(time.time() - start)/60.0:.2f}'\n",
    "log_file.write(f\"Finished Training after {training_time} minutes\\n\")\n",
    "print(f\"Finished Training after {training_time} minutes\")\n",
    "\n",
    "# Close the log file\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model after training\n",
    "torch.save(vgg16, \"../Models/vgg16_mnist.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Results and Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print final accuracy\n",
    "# get the final value of train_acc\n",
    "\n",
    "print(f\"Train Accuracy: {train_accs[-1]} %\")\n",
    "print(f\"Test Accuracy: {test_accs[-1]} %\")\n",
    "\n",
    "print(f\"Train Loss: {train_losses[-1]}\")\n",
    "print(f\"Test Loss: {test_losses[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix - VGG16 on MNIST\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and test loss over epochs\n",
    "plt.plot(train_losses, label=\"Training Loss\")\n",
    "plt.plot(test_losses, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss over Epochs - VGG16 on MNIST\")\n",
    "plt.legend()\n",
    "# save the plot\n",
    "plt.savefig(\"./plots/Loss_VGG16_MNIST.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training accuracy and test accuracy over epochs\n",
    "plt.plot(train_accs, label=\"Training Accuracy\")\n",
    "plt.plot(test_accs, label=\"Test Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy over Epochs - VGG16 on MNIST\")\n",
    "plt.legend()\n",
    "plt.savefig(\"./plots/Acc_VGG16_MNIST.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print classification report\n",
    "cr = classification_report(true_labels, predicted_labels)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading some images from the test set\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=30,shuffle=False)\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, true_labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes of mnist\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotter function to plot the images\n",
    "def plotter(images, true_labels, predicted_labels):\n",
    "    correct = 0\n",
    "    num_images = len(images)\n",
    "    num_rows = (num_images) // 5\n",
    "    fig, axs = plt.subplots(num_rows, 5, figsize=(15, 20))\n",
    "    # setting the title\n",
    "    fig.suptitle('True Label - [Predicted Labels]', fontsize=20)\n",
    "\n",
    "    for ind in range(num_images):\n",
    "        # plot image\n",
    "        img = images[ind].permute(1, 2, 0) / 2 + 0.5\n",
    "        ax = axs[ind // 5, ind % 5]\n",
    "        ax.imshow(img, cmap='gray')\n",
    "\n",
    "        # left - true label, right - predicted label\n",
    "        if classes[true_labels[ind]] == classes[predicted_labels[ind]]:\n",
    "            color = 'green'\n",
    "            title = classes[true_labels[ind]] + ' - [' + classes[predicted_labels[ind]] + ']'\n",
    "            ax.set_title(title, color=color)\n",
    "            correct += 1\n",
    "        else:\n",
    "            color = 'red'\n",
    "            title = classes[true_labels[ind]] + ' - [' + classes[predicted_labels[ind]] + ']'\n",
    "            ax.set_title(title, color=color)        \n",
    "\n",
    "    plt.tight_layout(pad=2.0)\n",
    "    plt.show()\n",
    "    print('Number of correct predictions: ', correct)\n",
    "    print('Number of wrong predictions: ', num_images - correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model to predict images label\n",
    "vgg16.eval()\n",
    "vgg16.to('cpu')\n",
    "outputs = vgg16(images)\n",
    "_, predicted_labels = torch.max(outputs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the images and predictions\n",
    "plotter(images, true_labels, predicted_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
