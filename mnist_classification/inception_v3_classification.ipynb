{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeper Networks for Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Inception V3 Model for MNIST Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Code by: Kaviraj Gosaye\n",
    "- Student ID: 220575371"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU details\n",
    "output = !nvidia-smi\n",
    "for line in output:\n",
    "    print(line)\n",
    "    if line.strip() == \"\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "# Get virtual memory information\n",
    "virtual_memory = psutil.virtual_memory()\n",
    "v_mem = virtual_memory.available / (1024 ** 3)\n",
    "\n",
    "# Print available virtual memory\n",
    "print(\"Available virtual memory:\", v_mem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torchinfo import summary\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import seaborn as sns\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "# load mnist dataset\n",
    "train_set = torchvision.datasets.MNIST(root='../datasets', train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.MNIST(root='../datasets', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract one sample from the training set\n",
    "dataiter = iter(train_loader)\n",
    "\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# plot the image\n",
    "def imshow(img):\n",
    "    # reverse normalization\n",
    "    img = img / 2 + 0.5\n",
    "    # convert tensor to numpy array\n",
    "    npimg = img.numpy()\n",
    "    # rearrange the dimensions to match matplotlib format\n",
    "    # matplotlib:   H x W x C\n",
    "    # torch:        C x H x W\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)\n",
    "\n",
    "class InceptionA(nn.Module):\n",
    "    def __init__(self, in_channels, pool_features):\n",
    "        super(InceptionA, self).__init__()\n",
    "        self.branch1x1 = BasicConv2d(in_channels, 64, kernel_size=1)\n",
    "\n",
    "        self.branch5x5_1 = BasicConv2d(in_channels, 48, kernel_size=1)\n",
    "        self.branch5x5_2 = BasicConv2d(48, 64, kernel_size=5, padding=2)\n",
    "\n",
    "        self.branch3x3dbl_1 = BasicConv2d(in_channels, 64, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = BasicConv2d(64, 96, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3 = BasicConv2d(96, 96, kernel_size=3, padding=1)\n",
    "\n",
    "        self.branch_pool = BasicConv2d(in_channels, pool_features, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch5x5, branch3x3dbl, branch_pool]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "class InceptionB(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(InceptionB, self).__init__()\n",
    "        self.branch3x3 = BasicConv2d(in_channels, 384, kernel_size=3, stride=2)\n",
    "\n",
    "        self.branch3x3dbl_1 = BasicConv2d(in_channels, 64, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = BasicConv2d(64, 96, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3 = BasicConv2d(96, 96, kernel_size=3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch3x3 = self.branch3x3(x)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "\n",
    "        branch_pool = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "\n",
    "        outputs = [branch3x3, branch3x3dbl, branch_pool]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "class InceptionC(nn.Module):\n",
    "    def __init__(self, in_channels, channels_7x7):\n",
    "        super(InceptionC, self).__init__()\n",
    "        self.branch1x1 = BasicConv2d(in_channels, 192, kernel_size=1)\n",
    "\n",
    "        c7 = channels_7x7\n",
    "        self.branch7x7_1 = BasicConv2d(in_channels, c7, kernel_size=1)\n",
    "        self.branch7x7_2 = BasicConv2d(c7, c7, kernel_size=(1, 7), padding=(0, 3))\n",
    "        self.branch7x7_3 = BasicConv2d(c7, 192, kernel_size=(7, 1), padding=(3, 0))\n",
    "\n",
    "        self.branch7x7dbl_1 = BasicConv2d(in_channels, c7, kernel_size=1)\n",
    "        self.branch7x7dbl_2 = BasicConv2d(c7, c7, kernel_size=(7, 1), padding=(3, 0))\n",
    "        self.branch7x7dbl_3 = BasicConv2d(c7, c7, kernel_size=(1, 7), padding=(0, 3))\n",
    "        self.branch7x7dbl_4 = BasicConv2d(c7, c7, kernel_size=(7, 1), padding=(3, 0))\n",
    "        self.branch7x7dbl_5 = BasicConv2d(c7, 192, kernel_size=(1, 7), padding=(0, 3))\n",
    "\n",
    "        self.branch_pool = BasicConv2d(in_channels, 192, kernel_size=1)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch7x7 = self.branch7x7_1(x)\n",
    "        branch7x7 = self.branch7x7_2(branch7x7)\n",
    "        branch7x7 = self.branch7x7_3(branch7x7)\n",
    "\n",
    "        branch7x7dbl = self.branch7x7dbl_1(x)\n",
    "        branch7x7dbl = self.branch7x7dbl_2(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_3(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_4(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_5(branch7x7dbl)\n",
    "        \n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "        \n",
    "        outputs = [branch1x1, branch7x7, branch7x7dbl, branch_pool]\n",
    "        return torch.cat(outputs, 1)\n",
    "    \n",
    "class InceptionD(nn.Module):\n",
    "\n",
    "    def __init__(self, input_channels):\n",
    "        super(InceptionD, self).__init__()\n",
    "\n",
    "        self.branch3x3_1 = BasicConv2d(input_channels, 192, kernel_size=1)\n",
    "        self.branch3x3_2 = BasicConv2d(192, 320, kernel_size=3, stride=2)\n",
    "        \n",
    "        self.branch7x7_1 = BasicConv2d(input_channels, 192, kernel_size=1)\n",
    "        self.branch7x7_2 = BasicConv2d(192, 192, kernel_size=(1, 7), padding=(0, 3))\n",
    "        self.branch7x7_3 = BasicConv2d(192, 192, kernel_size=(7, 1), padding=(3, 0))\n",
    "        self.branch7x7_4 = BasicConv2d(192, 192, kernel_size=3, stride=2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = self.branch3x3_2(branch3x3)\n",
    "\n",
    "        branch7x7 = self.branch7x7_1(x)\n",
    "        branch7x7 = self.branch7x7_2(branch7x7)\n",
    "        branch7x7 = self.branch7x7_3(branch7x7)\n",
    "        branch7x7 = self.branch7x7_4(branch7x7)\n",
    "\n",
    "        branch_pool = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "\n",
    "        outputs = [branch3x3, branch7x7, branch_pool]\n",
    "\n",
    "        return torch.cat(outputs, 1)\n",
    "    \n",
    "class InceptionE(nn.Module):\n",
    "\n",
    "    def __init__(self, input_channels):\n",
    "        super(InceptionE, self).__init__()\n",
    "\n",
    "        self.branch1x1 = BasicConv2d(input_channels, 320, kernel_size=1)\n",
    "\n",
    "        self.branch3x3_1 = BasicConv2d(input_channels, 384, kernel_size=1)\n",
    "        self.branch3x3_2a = BasicConv2d(384, 384, kernel_size=(1, 3), padding=(0, 1))\n",
    "        self.branch3x3_2b = BasicConv2d(384, 384, kernel_size=(3, 1), padding=(1, 0))\n",
    "\n",
    "        self.branch3x3dbl_1 = BasicConv2d(input_channels, 448, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = BasicConv2d(448, 384, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3a = BasicConv2d(384, 384, kernel_size=(1, 3), padding=(0, 1))\n",
    "        self.branch3x3dbl_3b = BasicConv2d(384, 384, kernel_size=(3, 1), padding=(1, 0))\n",
    "\n",
    "        self.branch_pool = BasicConv2d(input_channels, 192, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = [\n",
    "            self.branch3x3_2a(branch3x3),\n",
    "            self.branch3x3_2b(branch3x3)\n",
    "        ]\n",
    "        branch3x3 = torch.cat(branch3x3, 1)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = [\n",
    "            self.branch3x3dbl_3a(branch3x3dbl),\n",
    "            self.branch3x3dbl_3b(branch3x3dbl),\n",
    "        ]\n",
    "        branch3x3dbl = torch.cat(branch3x3dbl, 1)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch3x3, branch3x3dbl, branch_pool]\n",
    "        return torch.cat(outputs, 1)\n",
    "    \n",
    "class InceptionAux(nn.Module):\n",
    "    def __init__( self, in_channels, num_classes):\n",
    "        super(InceptionAux, self).__init__()\n",
    "    \n",
    "        self.conv0 = BasicConv2d(in_channels, 128, kernel_size=1)\n",
    "        self.conv1 = BasicConv2d(128, 768, kernel_size=5)\n",
    "        self.conv1.stddev = 0.01\n",
    "        self.fc = nn.Linear(768, num_classes)\n",
    "        self.fc.stddev = 0.001\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.avg_pool2d(x, kernel_size=5, stride=3)\n",
    "        x = self.conv0(x)\n",
    "        x = self.conv1(x)\n",
    "        # Adaptive average pooling\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionV3(nn.Module):\n",
    "    # setting use_aux to True will add an auxiliary classifier\n",
    "    def __init__(self, use_aux=False, num_classes=100):\n",
    "        super(InceptionV3, self).__init__()\n",
    "        \n",
    "        self.use_aux = use_aux\n",
    "\n",
    "        # same naming convention used for consistency\n",
    "        # replaced channels=3 with 1, kernel size 3 with 1, added stride=1\n",
    "        self.Conv2d_1a_3x3 = BasicConv2d(1, 32, kernel_size=1, padding=1, stride=1)\n",
    "        self.Conv2d_2a_3x3 = BasicConv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.Conv2d_2b_3x3 = BasicConv2d(32, 64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        \n",
    "        self.Conv2d_3b_1x1 = BasicConv2d(64, 80, kernel_size=1)\n",
    "        self.Conv2d_4a_3x3 = BasicConv2d(80, 192, kernel_size=3)\n",
    "\n",
    "        # replace maxpool with average pool\n",
    "        self.avgpool2 = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        \n",
    "        # inception modules\n",
    "        self.Mixed_5b = InceptionA(192, pool_features=32)\n",
    "        self.Mixed_5c = InceptionA(256, pool_features=64)\n",
    "        self.Mixed_5d = InceptionA(288, pool_features=64)\n",
    "\n",
    "        # inception modules\n",
    "        self.Mixed_6a = InceptionB(288)\n",
    "        self.Mixed_6b = InceptionC(768, channels_7x7=128)\n",
    "        self.Mixed_6c = InceptionC(768, channels_7x7=160)\n",
    "        self.Mixed_6d = InceptionC(768, channels_7x7=160)\n",
    "        self.Mixed_6e = InceptionC(768, channels_7x7=192)\n",
    "\n",
    "        # removed auxiliary layer\n",
    "        # if use_aux:\n",
    "        #     self.AuxLogits = InceptionAux(768, num_classes)\n",
    "\n",
    "        # inception modules\n",
    "        self.Mixed_7a = InceptionD(768)\n",
    "        self.Mixed_7b = InceptionE(1280)\n",
    "        self.Mixed_7c = InceptionE(2048)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout2d()\n",
    "        self.linear = nn.Linear(2048, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.Conv2d_1a_3x3(x)\n",
    "        x = self.Conv2d_2a_3x3(x)\n",
    "        x = self.Conv2d_2b_3x3(x)\n",
    "\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        x = self.Conv2d_3b_1x1(x)\n",
    "        x = self.Conv2d_4a_3x3(x)\n",
    "\n",
    "        x = self.avgpool2(x)\n",
    "\n",
    "        x = self.Mixed_5b(x)\n",
    "        x = self.Mixed_5c(x)\n",
    "        x = self.Mixed_5d(x)\n",
    "\n",
    "        x = self.Mixed_6a(x)\n",
    "\n",
    "        x = self.Mixed_6b(x)\n",
    "        x = self.Mixed_6c(x)\n",
    "        x = self.Mixed_6d(x)\n",
    "        x = self.Mixed_6e(x)\n",
    "\n",
    "        # if self.use_aux:\n",
    "        #     aux = self.AuxLogits(x)\n",
    "\n",
    "        x = self.Mixed_7a(x)\n",
    "        x = self.Mixed_7b(x)\n",
    "        x = self.Mixed_7c(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the device to cuda if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating instance of model and setting it to the device\n",
    "inception_v3 = InceptionV3(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the model\n",
    "info = summary(inception_v3, input_size=(1, 1, 28, 28), col_names = ('input_size', 'output_size', 'num_params', 'kernel_size'))\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(inception_v3.parameters(), lr=0.001)\n",
    "\n",
    "# open log file in write mode\n",
    "log_file = open(\"../logs/inceptionv3_mnist_log.txt\", \"w\")\n",
    "\n",
    "# training the model\n",
    "start = time.time()\n",
    "\n",
    "num_epochs = 10\n",
    "losses = []\n",
    "train_accs = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = inception_v3(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # cumulative loss\n",
    "        running_loss += loss.item()\n",
    "        # printing the average loss every 100 mini-batches\n",
    "        if i % 100 == 99:\n",
    "             # Get current timestamp\n",
    "            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            # Write loss to log file\n",
    "            log_file.write(f\"{timestamp} - [{epoch + 1}, {i + 1}] loss: {running_loss / 100}\\n\")\n",
    "            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 100}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "    correct = 0.0\n",
    "    pred = outputs.argmax(dim=1, keepdim=True)\n",
    "    # reshaping the labels to match the shape of the predictions\n",
    "    # comparing the predictions to the labels using element-wise comparison\n",
    "    # summing the correct predictions\n",
    "    correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "    train_acc = 100. * correct / len(outputs)\n",
    "    train_accs.append(train_acc)\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "print(f\"Finished Training after {time.time() - start} seconds\")\n",
    "\n",
    "# Close the log file\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model after training\n",
    "torch.save(inception_v3, \"../Models/inception_v3_mnist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_v3.to(device)\n",
    "inception_v3.eval()\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "    test_loss = 0\n",
    "\n",
    "    # Using test set\n",
    "    for data in test_loader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = inception_v3(images)\n",
    "        \n",
    "        # Calculate the test loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Get the predicted labels\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Update the total and correct predictions\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Append the predicted and true labels\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = 100 * correct / total\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "# Print the accuracy and test loss\n",
    "print(f\"Accuracy on the test data: {accuracy}%\")\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix - InceptionV3 on MNIST\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss of InceptionV3 on MNIST')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy\n",
    "plt.plot(train_accs)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy of InceptionV3 on MNIST')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to tensors\n",
    "pred_labels_tensor = torch.tensor(predicted_labels)\n",
    "true_labels_tensor = torch.tensor(true_labels)\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision = precision_score(true_labels_tensor, pred_labels_tensor, average='weighted')\n",
    "recall = recall_score(true_labels_tensor, pred_labels_tensor, average='weighted')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading some images from the test set\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=30,shuffle=False)\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, true_labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes of mnist\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotter function to plot the images\n",
    "def plotter(images, true_labels, predicted_labels):\n",
    "    correct = 0\n",
    "    num_images = len(images)\n",
    "    num_rows = (num_images) // 5\n",
    "    fig, axs = plt.subplots(num_rows, 5, figsize=(15, 20))\n",
    "    # setting the title\n",
    "    fig.suptitle('True Label - [Predicted Labels]', fontsize=20)\n",
    "\n",
    "    for ind in range(num_images):\n",
    "        # plot image\n",
    "        img = images[ind].permute(1, 2, 0) / 2 + 0.5\n",
    "        ax = axs[ind // 5, ind % 5]\n",
    "        ax.imshow(img, cmap='gray')\n",
    "\n",
    "        # left - true label, right - predicted label\n",
    "        if classes[true_labels[ind]] == classes[predicted_labels[ind]]:\n",
    "            color = 'green'\n",
    "            title = classes[true_labels[ind]] + ' - [' + classes[predicted_labels[ind]] + ']'\n",
    "            ax.set_title(title, color=color)\n",
    "            correct += 1\n",
    "        else:\n",
    "            color = 'red'\n",
    "            title = classes[true_labels[ind]] + ' - [' + classes[predicted_labels[ind]] + ']'\n",
    "            ax.set_title(title, color=color)        \n",
    "\n",
    "    plt.tight_layout(pad=2.0)\n",
    "    plt.show()\n",
    "    print('Number of correct predictions: ', correct)\n",
    "    print('Number of wrong predictions: ', num_images - correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model to predict images label\n",
    "inception_v3.eval()\n",
    "inception_v3.to('cpu')\n",
    "outputs = inception_v3(images)\n",
    "_, predicted_labels = torch.max(outputs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the images and predictions\n",
    "plotter(images, true_labels, predicted_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
